{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7554,"status":"ok","timestamp":1694860513753,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"ySovAqJZX0VW","outputId":"87c3b4d2-31e3-4f77-9b43-08f929d2bcb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pytorch-forecasting in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: fastapi\u003e=0.80 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (0.103.1)\n","Requirement already satisfied: lightning\u003c3.0.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.0.9)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (3.7.1)\n","Requirement already satisfied: optuna\u003c4.0.0,\u003e=3.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (3.3.0)\n","Requirement already satisfied: pandas\u003c=3.0.0,\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.5.3)\n","Requirement already satisfied: pytorch-optimizer\u003c3.0.0,\u003e=2.5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.11.2)\n","Requirement already satisfied: scikit-learn\u003c2.0,\u003e=1.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.2.2)\n","Requirement already satisfied: scipy\u003c2.0,\u003e=1.8 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.11.2)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (0.14.0)\n","Requirement already satisfied: torch\u003c3.0.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.0.1+cu118)\n","Requirement already satisfied: anyio\u003c4.0.0,\u003e=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi\u003e=0.80-\u003epytorch-forecasting) (3.7.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,\u003c3.0.0,\u003e=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi\u003e=0.80-\u003epytorch-forecasting) (1.10.12)\n","Requirement already satisfied: starlette\u003c0.28.0,\u003e=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi\u003e=0.80-\u003epytorch-forecasting) (0.27.0)\n","Requirement already satisfied: typing-extensions\u003e=4.5.0 in /usr/local/lib/python3.10/dist-packages (from fastapi\u003e=0.80-\u003epytorch-forecasting) (4.5.0)\n","Requirement already satisfied: Jinja2\u003c5.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (3.1.2)\n","Requirement already satisfied: PyYAML\u003c8.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (6.0.1)\n","Requirement already satisfied: arrow\u003c3.0,\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.2.3)\n","Requirement already satisfied: backoff\u003c4.0,\u003e=2.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.2.1)\n","Requirement already satisfied: beautifulsoup4\u003c6.0,\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (4.11.2)\n","Requirement already satisfied: click\u003c10.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (8.1.7)\n","Requirement already satisfied: croniter\u003c1.5.0,\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.4.1)\n","Requirement already satisfied: dateutils\u003c2.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (0.6.12)\n","Requirement already satisfied: deepdiff\u003c8.0,\u003e=5.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (6.5.0)\n","Requirement already satisfied: fsspec\u003c2025.0,\u003e=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2023.6.0)\n","Requirement already satisfied: inquirer\u003c5.0,\u003e=2.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (3.1.3)\n","Requirement already satisfied: lightning-cloud\u003e=0.5.38 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (0.5.38)\n","Requirement already satisfied: lightning-utilities\u003c2.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (0.9.0)\n","Requirement already satisfied: numpy\u003c3.0,\u003e=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (23.1)\n","Requirement already satisfied: psutil\u003c7.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (5.9.5)\n","Requirement already satisfied: python-multipart\u003c2.0,\u003e=0.0.5 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (0.0.6)\n","Requirement already satisfied: requests\u003c4.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.31.0)\n","Requirement already satisfied: rich\u003c15.0,\u003e=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (13.5.2)\n","Requirement already satisfied: starsessions\u003c2.0,\u003e=1.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.3.0)\n","Requirement already satisfied: torchmetrics\u003c3.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.1.2)\n","Requirement already satisfied: tqdm\u003c6.0,\u003e=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (4.66.1)\n","Requirement already satisfied: traitlets\u003c7.0,\u003e=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (5.7.1)\n","Requirement already satisfied: urllib3\u003c4.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.0.4)\n","Requirement already satisfied: uvicorn\u003c2.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (0.23.2)\n","Requirement already satisfied: websocket-client\u003c3.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.6.2)\n","Requirement already satisfied: websockets\u003c13.0 in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (11.0.3)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.0.9)\n","Requirement already satisfied: alembic\u003e=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna\u003c4.0.0,\u003e=3.1.0-\u003epytorch-forecasting) (1.12.0)\n","Requirement already satisfied: cmaes\u003e=0.10.0 in /usr/local/lib/python3.10/dist-packages (from optuna\u003c4.0.0,\u003e=3.1.0-\u003epytorch-forecasting) (0.10.0)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna\u003c4.0.0,\u003e=3.1.0-\u003epytorch-forecasting) (6.7.0)\n","Requirement already satisfied: sqlalchemy\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna\u003c4.0.0,\u003e=3.1.0-\u003epytorch-forecasting) (2.0.20)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003c=3.0.0,\u003e=1.3.0-\u003epytorch-forecasting) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003c=3.0.0,\u003e=1.3.0-\u003epytorch-forecasting) (2023.3.post1)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003c2.0,\u003e=1.2-\u003epytorch-forecasting) (1.3.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003c2.0,\u003e=1.2-\u003epytorch-forecasting) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (16.0.6)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003epytorch-forecasting) (1.1.0)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003epytorch-forecasting) (0.11.0)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003epytorch-forecasting) (4.42.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003epytorch-forecasting) (1.4.5)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003epytorch-forecasting) (9.4.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003epytorch-forecasting) (3.1.1)\n","Requirement already satisfied: patsy\u003e=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels-\u003epytorch-forecasting) (0.5.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna\u003c4.0.0,\u003e=3.1.0-\u003epytorch-forecasting) (1.2.4)\n","Requirement already satisfied: idna\u003e=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio\u003c4.0.0,\u003e=3.7.1-\u003efastapi\u003e=0.80-\u003epytorch-forecasting) (3.4)\n","Requirement already satisfied: sniffio\u003e=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio\u003c4.0.0,\u003e=3.7.1-\u003efastapi\u003e=0.80-\u003epytorch-forecasting) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio\u003c4.0.0,\u003e=3.7.1-\u003efastapi\u003e=0.80-\u003epytorch-forecasting) (1.1.3)\n","Requirement already satisfied: soupsieve\u003e1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4\u003c6.0,\u003e=4.8.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.5)\n","Requirement already satisfied: ordered-set\u003c4.2.0,\u003e=4.0.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff\u003c8.0,\u003e=5.7.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (4.1.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (3.8.5)\n","Requirement already satisfied: blessed\u003e=1.19.0 in /usr/local/lib/python3.10/dist-packages (from inquirer\u003c5.0,\u003e=2.10.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.20.0)\n","Requirement already satisfied: python-editor\u003e=1.0.4 in /usr/local/lib/python3.10/dist-packages (from inquirer\u003c5.0,\u003e=2.10.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.0.4)\n","Requirement already satisfied: readchar\u003e=3.0.6 in /usr/local/lib/python3.10/dist-packages (from inquirer\u003c5.0,\u003e=2.10.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (4.0.5)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2\u003c5.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.1.3)\n","Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud\u003e=0.5.38-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud\u003e=0.5.38-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.16.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c4.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (3.2.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c4.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2023.7.22)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003c15.0,\u003e=12.3.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003c15.0,\u003e=12.3.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.16.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy\u003e=1.3.0-\u003eoptuna\u003c4.0.0,\u003e=3.1.0-\u003epytorch-forecasting) (2.0.2)\n","Requirement already satisfied: itsdangerous\u003c3.0.0,\u003e=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions\u003c2.0,\u003e=1.2.1-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (2.1.2)\n","Requirement already satisfied: h11\u003e=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn\u003c2.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (0.14.0)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.3.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (23.1.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (6.0.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (4.0.3)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.9.2)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.4.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec\u003c2025.0,\u003e=2022.5.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (1.3.1)\n","Requirement already satisfied: wcwidth\u003e=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed\u003e=1.19.0-\u003einquirer\u003c5.0,\u003e=2.10.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (0.2.6)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003c15.0,\u003e=12.3.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (0.1.2)\n","Requirement already satisfied: setuptools\u003e=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar\u003e=3.0.6-\u003einquirer\u003c5.0,\u003e=2.10.0-\u003elightning\u003c3.0.0,\u003e=2.0.0-\u003epytorch-forecasting) (67.7.2)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["!pip install pytorch-forecasting\n","import torch\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import lightning.pytorch as pl\n","from lightning.pytorch.loggers import TensorBoardLogger\n","from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n","from lightning.pytorch.tuner import Tuner\n","\n","from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n","from pytorch_forecasting.data import GroupNormalizer\n","from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n","from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n","from pytorch_forecasting.metrics import MultiHorizonMetric\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import random\n","import os\n","from tqdm.auto import tqdm\n","import numpy as np\n","import pandas as pd\n","import pickle"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":23372,"status":"ok","timestamp":1694860537120,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"6__Wk5VNX8iu"},"outputs":[],"source":["train_df = pd.read_parquet('/content/drive/MyDrive/Colab Notebooks/Data/final/preprocessed_train_7.parquet')\n","test_df = pd.read_parquet(\"/content/drive/MyDrive/Colab Notebooks/Data/final/preprocessed_test_7.parquet\")\n","train_csv = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/final/train.csv')\n","sample_submission_csv = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/final/sample_submission.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":233296,"status":"ok","timestamp":1694860770404,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"eTI3Gs8cX-q5","outputId":"732e389b-8647-438e-e815-17037f66a460"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_df['month'] = train_df['month'].astype(str)\n","train_df['time_idx'] = train_df['time_idx'].astype(int)\n","train_df['sales_rate'] = train_df['sales_rate'].astype(float)\n","train_df['week_weekend'] = train_df['week_weekend'].astype(str)\n","train_df['special_day'] = train_df['special_day'].astype(str)\n","\n","test_df['month'] = test_df['month'].astype(str)\n","test_df['time_idx'] = test_df['time_idx'].astype(int)\n","test_df['sales_rate'] = test_df['sales_rate'].astype(float)\n","test_df['week_weekend'] = test_df['week_weekend'].astype(str)\n","test_df['special_day'] = test_df['special_day'].astype(str)\n","\n","max_prediction_length = 21\n","min_prediction_length = 21\n","max_encoder_length = 90\n","validation_duration = 0\n","training_cutoff = train_df[\"time_idx\"].max() - (max_prediction_length + validation_duration)\n","\n","mid_train_df_2 = train_df[train_df['time_idx'] \u003c= (train_df[\"time_idx\"].max() // 1.15)]\n","training_cutoff_2 = train_df[\"time_idx\"].max() - (max_prediction_length + validation_duration)\n","\n","training = TimeSeriesDataSet(\n","    train_df[lambda x: x['time_idx'] \u003c= training_cutoff],\n","    time_idx=\"time_idx\",\n","    target=\"sales_rate\",\n","    group_ids=['product_nums'],\n","    min_encoder_length=max_encoder_length,\n","    max_encoder_length=max_encoder_length,\n","    min_prediction_length=min_prediction_length,\n","    max_prediction_length=max_prediction_length,\n","    static_categoricals=[\"major\", \"middle\", 'sub', 'brand'],\n","    static_reals=[],\n","    time_varying_known_categoricals=['month', 'week_weekend', 'special_day', 'day'],\n","    time_varying_known_reals=[\"keyword_cnt\"],\n","    time_varying_unknown_categoricals=[],\n","    time_varying_unknown_reals=[\n","        'sales_rate', \"average_month_sales_rate\",'sales_rate_log','sales'],\n","    target_normalizer = GroupNormalizer(groups=[\"product_nums\"], transformation = 'softplus', method=\"standard\"),\n","    add_relative_time_idx=True,\n","    add_target_scales=True,\n","    add_encoder_length=True,\n",")\n","\n","# synchronized는 끄면 psfa_1, 켜면 psfa_2\n","batch_size = 1589  # set this between 32 to 128\n","# validation = TimeSeriesDataSet.from_dataset(training, train_df, predict=True, stop_randomization=True)\n","validation = TimeSeriesDataSet.from_dataset(training, train_df, predict=True, stop_randomization=True)\n","train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=12)\n","val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=12)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1845,"status":"ok","timestamp":1694860772238,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"0OjTpLnihet2"},"outputs":[],"source":["# 1. Load the study from study_path\n","dataset_name = 'dataset_4'\n","\n","study_path = f\"/content/drive/MyDrive/Colab Notebooks/Kkh/data/optuna_best_parameter/{dataset_name}/best_parameter_study.pkl\"\n","with open(study_path, \"rb\") as f:\n","    study = pickle.load(f)\n","\n","# 2. Get the best hyperparameters from the study\n","best_hyperparameters = study.best_trial.params"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1694860772239,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"OBX-8TyoIEHt"},"outputs":[],"source":["# psfa_1: synchronized 옵션 끈 상태\n","class PSFA_1(MultiHorizonMetric):\n","    def loss(self, y_pred, target):\n","        y_pred = self.to_prediction(y_pred)\n","        diff_value = torch.abs(target - y_pred)\n","        max_value = torch.max(target, y_pred) + 1e-8\n","        weight_denumerator = torch.sum(target, axis=1).view(y_pred.shape[0], 1) + 1e-8\n","        weight = target / weight_denumerator\n","        loss = ((diff_value / max_value) * weight) * (y_pred.shape[1])\n","        return loss\n","\n","# psfa_2: synchronized 옵션 킨 상태\n","class PSFA_2(MultiHorizonMetric):\n","    def loss(self, y_pred, target):\n","        y_pred = self.to_prediction(y_pred)\n","        diff_value = torch.abs(target - y_pred)\n","        max_value = torch.max(target, y_pred) + 1e-8\n","        # 위까지가 (1589, 21)\n","\n","        # 행을 더한다 = 같은일자의 1589개의 품목을 더한다 = (1, 21)이 나온다.\n","        weight_denumerator = torch.sum(target, axis=0).view(1, y_pred.shape[1]) + 1e-8\n","        weight = target / weight_denumerator\n","        loss = ((diff_value / max_value) * weight) * (y_pred.shape[0])\n","        return loss\n","\n","class SMAPE(MultiHorizonMetric):\n","    def loss(self, y_pred, target):\n","        y_pred = self.to_prediction(y_pred)\n","        print(f\"1. y_pred의 shape {y_pred.shape}\")\n","        loss =  (y_pred - target).abs() / ((y_pred.abs() + target.abs() + 1e-8)/2)\n","        print(f\"2. loss shape {loss.shape}\")\n","        return loss"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1970,"status":"ok","timestamp":1694860774206,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"o-Q-EhnutI4g","outputId":"eed9a0a8-2e67-4d63-88e2-953ad53f81eb"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n","  rank_zero_warn(\n","/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["Number of parameters in network: 607.1k\n"]}],"source":["early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n","checkpoint_callback = ModelCheckpoint(save_top_k=20, monitor = 'val_loss', mode = 'min', dirpath =f\"/content/drive/MyDrive/Colab Notebooks/Kkh/data/optuna_record_checkpoint/final\", filename = \"final-{epoch:02d}-{val_loss:.7f}\" )\n","lr_logger = LearningRateMonitor()  # log the learning rate\n","logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n","\n","trainer = pl.Trainer(\n","    max_epochs=2,\n","    accelerator=\"gpu\",\n","    gradient_clip_val=best_hyperparameters['gradient_clip_val'],\n","    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n","    callbacks=[lr_logger, early_stop_callback, checkpoint_callback],\n","    logger=logger,\n",")\n","\n","tft = TemporalFusionTransformer.from_dataset(\n","    training,\n","    learning_rate=best_hyperparameters['learning_rate'],\n","    hidden_size=best_hyperparameters['hidden_size'],\n","    attention_head_size=best_hyperparameters['attention_head_size'],\n","    dropout=best_hyperparameters['dropout'],\n","    hidden_continuous_size=best_hyperparameters['hidden_continuous_size'],\n","    loss=PSFA_2(),\n","    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n","    optimizer=\"Ranger\",\n","    reduce_on_plateau_patience=4,\n",")\n","print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13249,"status":"ok","timestamp":1694860787452,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"isJJshdWtVL4","outputId":"2191926d-8c81-403e-d229-381e1d72a04c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.3.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n","  rank_zero_warn(\n","/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n","  rank_zero_warn(\n"]}],"source":["best_model_path = '/content/drive/MyDrive/Colab Notebooks/Data/final/model/230916-nopinfo-psfa_1-epoch=06-val_loss=0.221639-train_loss_epoch=0.252218.ckpt'\n","tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1349181,"status":"ok","timestamp":1694784857150,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"aOyJUiG7c2sc","outputId":"a79be302-4a07-4b1b-92eb-e504616b43c5"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","   | Name                               | Type                            | Params\n","----------------------------------------------------------------------------------------\n","0  | loss                               | PSFA_2                          | 0     \n","1  | logging_metrics                    | ModuleList                      | 0     \n","2  | input_embeddings                   | MultiEmbedding                  | 265 K \n","3  | prescalers                         | ModuleDict                      | 216   \n","4  | static_variable_selection          | VariableSelectionNetwork        | 11.4 K\n","5  | encoder_variable_selection         | VariableSelectionNetwork        | 20.1 K\n","6  | decoder_variable_selection         | VariableSelectionNetwork        | 7.5 K \n","7  | static_context_variable_selection  | GatedResidualNetwork            | 26.7 K\n","8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 26.7 K\n","9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 26.7 K\n","10 | static_context_enrichment          | GatedResidualNetwork            | 26.7 K\n","11 | lstm_encoder                       | LSTM                            | 53.1 K\n","12 | lstm_decoder                       | LSTM                            | 53.1 K\n","13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 13.3 K\n","14 | post_lstm_add_norm_encoder         | AddNorm                         | 162   \n","15 | static_enrichment                  | GatedResidualNetwork            | 33.3 K\n","16 | multihead_attn                     | InterpretableMultiHeadAttention | 19.6 K\n","17 | post_attn_gate_norm                | GateAddNorm                     | 13.4 K\n","18 | pos_wise_ff                        | GatedResidualNetwork            | 26.7 K\n","19 | pre_output_gate_norm               | GateAddNorm                     | 13.4 K\n","20 | output_layer                       | Linear                          | 82    \n","----------------------------------------------------------------------------------------\n","637 K     Trainable params\n","0         Non-trainable params\n","637 K     Total params\n","2.550     Total estimated model params size (MB)\n","INFO:lightning.pytorch.callbacks.model_summary:\n","   | Name                               | Type                            | Params\n","----------------------------------------------------------------------------------------\n","0  | loss                               | PSFA_2                          | 0     \n","1  | logging_metrics                    | ModuleList                      | 0     \n","2  | input_embeddings                   | MultiEmbedding                  | 265 K \n","3  | prescalers                         | ModuleDict                      | 216   \n","4  | static_variable_selection          | VariableSelectionNetwork        | 11.4 K\n","5  | encoder_variable_selection         | VariableSelectionNetwork        | 20.1 K\n","6  | decoder_variable_selection         | VariableSelectionNetwork        | 7.5 K \n","7  | static_context_variable_selection  | GatedResidualNetwork            | 26.7 K\n","8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 26.7 K\n","9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 26.7 K\n","10 | static_context_enrichment          | GatedResidualNetwork            | 26.7 K\n","11 | lstm_encoder                       | LSTM                            | 53.1 K\n","12 | lstm_decoder                       | LSTM                            | 53.1 K\n","13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 13.3 K\n","14 | post_lstm_add_norm_encoder         | AddNorm                         | 162   \n","15 | static_enrichment                  | GatedResidualNetwork            | 33.3 K\n","16 | multihead_attn                     | InterpretableMultiHeadAttention | 19.6 K\n","17 | post_attn_gate_norm                | GateAddNorm                     | 13.4 K\n","18 | pos_wise_ff                        | GatedResidualNetwork            | 26.7 K\n","19 | pre_output_gate_norm               | GateAddNorm                     | 13.4 K\n","20 | output_layer                       | Linear                          | 82    \n","----------------------------------------------------------------------------------------\n","637 K     Trainable params\n","0         Non-trainable params\n","637 K     Total params\n","2.550     Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5966d752c9546368abd153ecec46791","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbad028f307d467980ec592d9ad40dbb","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# trainer.fit(\n","#     tft,\n","#     train_dataloaders=train_dataloader,\n","#     val_dataloaders=val_dataloader\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"IeJWkixMigMJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-09-16 10:44:43,196] A new study created in memory with name: no-name-03c16bc7-faa3-401c-93fe-30eae647ad5a\n","/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:124: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  gradient_clip_val = trial.suggest_loguniform(\"gradient_clip_val\", *gradient_clip_val_range)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:148: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  dropout=trial.suggest_uniform(\"dropout\", *dropout_range),\n","/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n","  rank_zero_warn(\n","/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n","  rank_zero_warn(\n","/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:196: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  model.hparams.learning_rate = trial.suggest_loguniform(\"learning_rate\", *learning_rate_range)\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n","[I 2023-09-16 12:12:47,814] Trial 0 finished with value: 9.647595405578613 and parameters: {'gradient_clip_val': 0.27356558898834454, 'hidden_size': 54, 'dropout': 0.27502635274983633, 'hidden_continuous_size': 46, 'attention_head_size': 1, 'learning_rate': 0.031475393111542606}. Best is trial 0 with value: 9.647595405578613.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n","[I 2023-09-16 13:32:04,012] Trial 1 finished with value: 11.687626838684082 and parameters: {'gradient_clip_val': 0.08070559341246607, 'hidden_size': 25, 'dropout': 0.19097141137364682, 'hidden_continuous_size': 10, 'attention_head_size': 3, 'learning_rate': 0.022891205798256008}. Best is trial 0 with value: 9.647595405578613.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n","[I 2023-09-16 15:01:21,513] Trial 2 finished with value: 10.570493698120117 and parameters: {'gradient_clip_val': 0.013694152455667578, 'hidden_size': 113, 'dropout': 0.2517178250894977, 'hidden_continuous_size': 19, 'attention_head_size': 1, 'learning_rate': 0.03711815699758582}. Best is trial 0 with value: 9.647595405578613.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n","[I 2023-09-16 16:19:05,117] Trial 3 finished with value: 9.708115577697754 and parameters: {'gradient_clip_val': 0.5543964869960432, 'hidden_size': 18, 'dropout': 0.1889527860404291, 'hidden_continuous_size': 11, 'attention_head_size': 3, 'learning_rate': 0.05320087490487123}. Best is trial 0 with value: 9.647595405578613.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n","[I 2023-09-16 17:49:08,369] Trial 4 finished with value: 10.90740966796875 and parameters: {'gradient_clip_val': 0.28024876962215356, 'hidden_size': 110, 'dropout': 0.10011533871434636, 'hidden_continuous_size': 12, 'attention_head_size': 2, 'learning_rate': 0.004752931760197102}. Best is trial 0 with value: 9.647595405578613.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n","[I 2023-09-16 19:14:33,074] Trial 5 finished with value: 9.853296279907227 and parameters: {'gradient_clip_val': 0.06624330560469363, 'hidden_size': 47, 'dropout': 0.1511794055736049, 'hidden_continuous_size': 39, 'attention_head_size': 4, 'learning_rate': 0.004977317356022191}. Best is trial 0 with value: 9.647595405578613.\n"]},{"name":"stdout","output_type":"stream","text":["{'gradient_clip_val': 0.27356558898834454, 'hidden_size': 54, 'dropout': 0.27502635274983633, 'hidden_continuous_size': 46, 'attention_head_size': 1, 'learning_rate': 0.031475393111542606}\n"]}],"source":["# 아래 코드는 한 번 중지하면 세션이 꺼져버린다. 주의해서 실행할 것\n","optuna_record_path = \"/content/drive/MyDrive/Colab Notebooks/Kkh/data/optuna_record_checkpoint/final\"\n","study_path = f\"/content/drive/MyDrive/Colab Notebooks/Kkh/data/optuna_best_parameter/final/final_parameter.pkl\"\n","\n","\n","# create study\n","study = optimize_hyperparameters(\n","    train_dataloader,\n","    val_dataloader,\n","    model_path=optuna_record_path,\n","    # n_trials=1,\n","    # max_epochs=1,\n","    n_trials=10,\n","    max_epochs=50,\n","    gradient_clip_val_range=(0.01, 1.0),\n","    hidden_size_range=(8, 128),\n","    hidden_continuous_size_range=(8, 128),\n","    attention_head_size_range=(1, 4),\n","    learning_rate_range=(0.001, 0.1),\n","    dropout_range=(0.1, 0.3),\n","    trainer_kwargs=dict(limit_train_batches=50),\n","    reduce_on_plateau_patience=100,\n","    use_learning_rate_finder=False, # use Optuna to find ideal learning rate or use in-built learning rate finder\n",")\n","\n","# save study results - also we can resume tuning at a later point in time\n","with open(study_path, \"wb\") as f:\n","    pickle.dump(study, f)\n","\n","# show best hyperparameters\n","print(study.best_trial.params)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":631,"status":"ok","timestamp":1691761503054,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"yBafPuUk0H4c","outputId":"1c0a78d2-b31f-4297-a21b-61736ec65c70"},"outputs":[{"data":{"text/plain":["{'gradient_clip_val': 0.8369364469185068,\n"," 'hidden_size': 26,\n"," 'dropout': 0.2271421770302028,\n"," 'hidden_continuous_size': 16,\n"," 'attention_head_size': 2,\n"," 'learning_rate': 0.0033604196637294107}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# 1. Load the study from study_path\n","\n","dataset_name = 'dataset_6'\n","test_id = '230810-0'\n","\n","study_path = f\"/content/drive/MyDrive/Colab Notebooks/Kkh/data/optuna_best_parameter/{dataset_name}/best_parameter_study.pkl\"\n","with open(study_path, \"rb\") as f:\n","    study = pickle.load(f)\n","\n","# 2. Get the best hyperparameters from the study\n","best_hyperparameters = study.best_trial.params\n","best_hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":736,"status":"ok","timestamp":1691639039525,"user":{"displayName":"LG_Aimers_3rd연정환호","userId":"07699757122921819095"},"user_tz":-540},"id":"zol4w24j0Mqr","outputId":"43fbb898-d01e-4cc5-96cf-f51716482725"},"outputs":[{"data":{"text/plain":["{'gradient_clip_val': 0.03737036693440084,\n"," 'hidden_size': 81,\n"," 'dropout': 0.28740217775266835,\n"," 'hidden_continuous_size': 12,\n"," 'attention_head_size': 2,\n"," 'learning_rate': 0.00585230984542428}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# 1. Load the study from study_path\n","\n","dataset_name = 'dataset_4'\n","test_id = '230809-0'\n","\n","study_path = f\"/content/drive/MyDrive/Colab Notebooks/Kkh/data/optuna_best_parameter/{dataset_name}/best_parameter_study.pkl\"\n","with open(study_path, \"rb\") as f:\n","    study = pickle.load(f)\n","\n","# 2. Get the best hyperparameters from the study\n","best_hyperparameters = study.best_trial.params\n","best_hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"OyQW2CAdS09I"},"source":["# Dataset_2 실험 결과 정리\n","  1. 데이터셋은 위와 같다.\n","    * 특이점 : product를 칼럼에서 제외하였다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VVaLQl_pfj8W"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOFptLfsLxgEeazWsdSN82M","machine_shape":"hm","mount_file_id":"1l6sDW4NF5XV4spWO0c4jk9Cqp--7ubBO","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"089b797fb8c64a92888e63b148120e08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a7584ccbfdd4945a1c013003fdd9634":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c13c96c3eaf4d63b200beb0b04c2c7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_335c8d989bb74340a0ed6528f2153f47","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a7584ccbfdd4945a1c013003fdd9634","value":2}},"0f270460b3fb4532945a65312868367e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"1bc311904b4a411393303476e9965361":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bec0adbccdb4093985242af44822b3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"335c8d989bb74340a0ed6528f2153f47":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34ac7bc7e35946f0acce914b02594abe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46810aa9acc04324be58c7cff4baefcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4808687e86234951b5c99253b403049a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"587d8702ee5b4768aaf78d68629e096d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6be7bd64cc5b4f65b48d07f13ec33153":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c74ad9b21584b6584f49442ee1c28d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"768573a81f2b4f32a4811c8bd78a4513":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_089b797fb8c64a92888e63b148120e08","placeholder":"​","style":"IPY_MODEL_46810aa9acc04324be58c7cff4baefcb","value":" 2/2 [00:02\u0026lt;00:00,  1.04s/it]"}},"830813717fdc4f6d8197684f8c965ef8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5f0fe1d6aaf4498a9a856b9e4ab65c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4808687e86234951b5c99253b403049a","placeholder":"​","style":"IPY_MODEL_6c74ad9b21584b6584f49442ee1c28d3","value":" 720/3280 [21:56\u0026lt;1:17:59,  1.83s/it, v_num=1, train_loss_step=0.358]"}},"baeabe32c3e347cdb0fd8c71a6dc8b4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_830813717fdc4f6d8197684f8c965ef8","placeholder":"​","style":"IPY_MODEL_1bc311904b4a411393303476e9965361","value":"Epoch 0:  22%"}},"c75edb00dc7e46a5b2a0d8975a5d66ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"d573db9bb5504ceaaf0c16f903100271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6be7bd64cc5b4f65b48d07f13ec33153","max":3280,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34ac7bc7e35946f0acce914b02594abe","value":720}},"dbad028f307d467980ec592d9ad40dbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_baeabe32c3e347cdb0fd8c71a6dc8b4e","IPY_MODEL_d573db9bb5504ceaaf0c16f903100271","IPY_MODEL_a5f0fe1d6aaf4498a9a856b9e4ab65c6"],"layout":"IPY_MODEL_c75edb00dc7e46a5b2a0d8975a5d66ff"}},"e5966d752c9546368abd153ecec46791":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f88730239ed443d1a287c99cf6296ed0","IPY_MODEL_0c13c96c3eaf4d63b200beb0b04c2c7a","IPY_MODEL_768573a81f2b4f32a4811c8bd78a4513"],"layout":"IPY_MODEL_0f270460b3fb4532945a65312868367e"}},"f88730239ed443d1a287c99cf6296ed0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_587d8702ee5b4768aaf78d68629e096d","placeholder":"​","style":"IPY_MODEL_2bec0adbccdb4093985242af44822b3d","value":"Sanity Checking DataLoader 0: 100%"}}}}},"nbformat":4,"nbformat_minor":0}